{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f52d03",
   "metadata": {},
   "source": [
    "# PyTorch blend model\n",
    "Each model will have 4 features:\n",
    "1. torch.cos(3 * (azi - 0.15788))**50\n",
    "2. xyz\n",
    "\n",
    "Use `1 - CosineSimilarity` for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b9f89e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T10:11:22.934014Z",
     "start_time": "2023-04-13T10:11:17.666041Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from transformers import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34ecba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T10:11:22.939190Z",
     "start_time": "2023-04-13T10:11:22.936317Z"
    }
   },
   "outputs": [],
   "source": [
    "oofs = [\n",
    "    \"/mnt/storage_dimm2/kaggle_output/icecube-neutrinos-in-deep-ice/20230323-102724/DynEdge/fold_0/oofs.parquet\",\n",
    "    \"/mnt/storage_dimm2/kaggle_output/icecube-neutrinos-in-deep-ice/20230409-080525/DynEdge/fold_0/oofs.parquet\",\n",
    "    \"/mnt/storage_dimm2/kaggle_output/icecube-neutrinos-in-deep-ice/20230405-063040/GPS/fold_0/oofs.parquet\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b881b04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T10:11:23.398954Z",
     "start_time": "2023-04-13T10:11:22.943371Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_df = {}\n",
    "\n",
    "for i, oof in enumerate(oofs):\n",
    "    df = pd.read_parquet(oof)\n",
    "    oof_df[f\"model_{i}_azi\"] = df[\"azimuth\"]\n",
    "    oof_df[f\"model_{i}_zen\"] = df[\"zenith\"]\n",
    "    \n",
    "oof_df[\"azimuth_gt\"] = df[\"azimuth_gt\"]\n",
    "oof_df[\"zenith_gt\"] = df[\"zenith_gt\"]\n",
    "\n",
    "oof_df = pd.DataFrame(oof_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0bd5852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T10:11:23.410949Z",
     "start_time": "2023-04-13T10:11:23.400954Z"
    }
   },
   "outputs": [],
   "source": [
    "class StackDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.num_models = len(df.columns) // 2\n",
    "        self.train = False\n",
    "        \n",
    "        if \"azimuth_gt\" in df.columns:\n",
    "            self.num_models -= 1\n",
    "            self.train = True\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def angles_to_xyz(self, azimuth, zenith):\n",
    "        x = torch.cos(azimuth) * torch.sin(zenith)\n",
    "        y = torch.sin(azimuth) * torch.sin(zenith)\n",
    "        z = torch.cos(zenith)\n",
    "        return torch.cat([x, y, z])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        obs = self.df.iloc[idx]\n",
    "        features = []\n",
    "        \n",
    "        for i in range(self.num_models):\n",
    "            azi = torch.tensor([obs[f\"model_{i}_azi\"]], dtype=torch.float32)\n",
    "            zen = torch.tensor([obs[f\"model_{i}_zen\"]], dtype=torch.float32)\n",
    "            xyz = self.angles_to_xyz(azi, zen)\n",
    "            periodic = (torch.cos(3 * (azi - 0.15788))**50)\n",
    "            features.extend([xyz, periodic])\n",
    "            \n",
    "        features = torch.cat(features)\n",
    "        \n",
    "        if self.train:\n",
    "            azi_gt = torch.tensor([obs[\"azimuth_gt\"]], dtype=torch.float32)\n",
    "            zen_gt = torch.tensor([obs[\"zenith_gt\"]], dtype=torch.float32)\n",
    "            target = self.angles_to_xyz(azi_gt, zen_gt)\n",
    "        else:\n",
    "            target = None\n",
    "            \n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21215c8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T10:11:23.422091Z",
     "start_time": "2023-04-13T10:11:23.413886Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_folds(data, n_splits=5, random_state=48):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    data[\"fold\"] = -1\n",
    "\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=data)):\n",
    "        data.loc[v_, \"fold\"] = f\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "class StackDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, data, batch_size: int = 32, num_workers: int = 8):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.data = create_folds(data)\n",
    "        self.train_steps = 0\n",
    "\n",
    "    def setup(self, stage=None, fold_n: int = 0):\n",
    "\n",
    "        if stage == \"fit\" or stage == \"predict\":\n",
    "            trn_df = self.data.query(f\"fold != {fold_n}\")\n",
    "            val_df = self.data.query(f\"fold == {fold_n}\")\n",
    "            del trn_df[\"fold\"]\n",
    "            del val_df[\"fold\"]\n",
    "\n",
    "            self.train_ds = StackDataset(trn_df)\n",
    "            self.valid_ds = StackDataset(val_df)\n",
    "            self.train_steps = len(self.train_ds) / self.batch_size\n",
    "            print(len(self.train_ds), \"train and\", len(self.valid_ds),\n",
    "                  \"valid samples\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            num_workers=self.num_workers,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            pin_memory=True,\n",
    "            # persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valid_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            # persistent_workers=True,\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valid_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abcf1a2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T10:11:23.429746Z",
     "start_time": "2023-04-13T10:11:23.424409Z"
    }
   },
   "outputs": [],
   "source": [
    "def angular_dist_score(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    calculate the MAE of the angular distance between two directions.\n",
    "    The two vectors are first converted to cartesian unit vectors,\n",
    "    and then their scalar product is computed, which is equal to\n",
    "    the cosine of the angle between the two vectors. The inverse\n",
    "    cosine (arccos) thereof is then the angle between the two input vectors\n",
    "\n",
    "    # https://www.kaggle.com/code/sohier/mean-angular-error\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    y_pred : float (torch.Tensor)\n",
    "        Prediction array of [N, 2], where the second dim is azimuth & zenith\n",
    "    y_true : float (torch.Tensor)\n",
    "        Ground truth array of [N, 2], where the second dim is azimuth & zenith\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "\n",
    "    dist : float (torch.Tensor)\n",
    "        mean over the angular distance(s) in radian\n",
    "    \"\"\"\n",
    "\n",
    "    az_true = y_true[:, 0]\n",
    "    zen_true = y_true[:, 1]\n",
    "\n",
    "    az_pred = y_pred[:, 0]\n",
    "    zen_pred = y_pred[:, 1]\n",
    "\n",
    "    # pre-compute all sine and cosine values\n",
    "    sa1 = torch.sin(az_true)\n",
    "    ca1 = torch.cos(az_true)\n",
    "    sz1 = torch.sin(zen_true)\n",
    "    cz1 = torch.cos(zen_true)\n",
    "\n",
    "    sa2 = torch.sin(az_pred)\n",
    "    ca2 = torch.cos(az_pred)\n",
    "    sz2 = torch.sin(zen_pred)\n",
    "    cz2 = torch.cos(zen_pred)\n",
    "\n",
    "    # scalar product of the two cartesian vectors (x = sz*ca, y = sz*sa, z = cz)\n",
    "    scalar_prod = sz1 * sz2 * (ca1 * ca2 + sa1 * sa2) + (cz1 * cz2)\n",
    "\n",
    "    # scalar product of two unit vectors is always between -1 and 1, this is against nummerical instability\n",
    "    # that might otherwise occure from the finite precision of the sine and cosine functions\n",
    "    scalar_prod = torch.clamp(scalar_prod, -1, 1)\n",
    "\n",
    "    # convert back to an angle (in radian)\n",
    "    return torch.mean(torch.abs(torch.arccos(scalar_prod)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d098f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T10:11:23.436460Z",
     "start_time": "2023-04-13T10:11:23.432015Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_weight_decay(\n",
    "    model,\n",
    "    weight_decay=1e-5,\n",
    "    skip_list=(\"bias\", \"bn\", \"LayerNorm.bias\", \"LayerNorm.weight\"),\n",
    "):\n",
    "    decay = []\n",
    "    no_decay = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # frozen weights\n",
    "        if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list:\n",
    "            no_decay.append(param)\n",
    "        else:\n",
    "            decay.append(param)\n",
    "    return [\n",
    "        {\"params\": no_decay, \"weight_decay\": 0.0},\n",
    "        {\"params\": decay, \"weight_decay\": weight_decay},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c920bbc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T10:11:23.448516Z",
     "start_time": "2023-04-13T10:11:23.438615Z"
    }
   },
   "outputs": [],
   "source": [
    "class StackModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nb_models: int = 3,\n",
    "        model_name: str = \"StackModel\",\n",
    "        learning_rate: float = 0.0001,\n",
    "        weight_decay: float = 0.01,\n",
    "        eps: float = 1e-8,\n",
    "        warmup: float = 0.0,\n",
    "        T_max: int = 1000,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.loss_fn = nn.CosineSimilarity()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(nb_models * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def xyz_to_angles(self, xyz):\n",
    "        x = xyz[:, 0]\n",
    "        y = xyz[:, 1]\n",
    "        z = xyz[:, 2]\n",
    "        r = torch.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "        zen = torch.arccos(z / r)\n",
    "        azi = torch.arctan2(y, x)\n",
    "\n",
    "        return torch.stack([azi, zen], dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, target = batch\n",
    "        pred_xyz = self.forward(features)\n",
    "\n",
    "        loss = 1 - self.loss_fn(pred_xyz, target).mean()\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        features, target = batch\n",
    "        pred_xyz = self.forward(features)\n",
    "\n",
    "        loss = 1 - self.loss_fn(pred_xyz, target).mean()\n",
    "\n",
    "        pred_angles = self.xyz_to_angles(pred_xyz)\n",
    "        target_angles = self.xyz_to_angles(target)\n",
    "        metric = angular_dist_score(pred_angles, target_angles)\n",
    "\n",
    "        self.log(\n",
    "            \"metric\",\n",
    "            metric,\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "            on_epoch=True,\n",
    "#             batch_size=self.hparams.batch_size,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        parameters = add_weight_decay(\n",
    "            self,\n",
    "            self.hparams.weight_decay,\n",
    "            skip_list=[\"bias\", \"LayerNorm.bias\"],  # , \"LayerNorm.weight\"],\n",
    "        )\n",
    "\n",
    "        opt = torch.optim.AdamW(parameters,\n",
    "                                lr=self.hparams.learning_rate,\n",
    "                                eps=self.hparams.eps)\n",
    "\n",
    "        sch = get_cosine_schedule_with_warmup(\n",
    "            opt,\n",
    "            num_warmup_steps=int(self.hparams.warmup * self.hparams.T_max),\n",
    "            num_training_steps=self.hparams.T_max,\n",
    "            num_cycles=0.5,  # 1,\n",
    "            last_epoch=-1,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": opt,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": sch,\n",
    "                \"interval\": \"step\"\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bef633",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a6cc67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T10:20:19.563573Z",
     "start_time": "2023-04-13T10:11:23.451644Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056768 train and 264192 valid samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjum/venv/kaggle/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=2)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | loss_fn | CosineSimilarity | 0     \n",
      "1 | model   | Sequential       | 18.6 K\n",
      "---------------------------------------------\n",
      "18.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.6 K    Total params\n",
      "0.074     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056768 train and 264192 valid samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a722c05c04dd4deeb6a3316e3bae8d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "dm = StackDataModule(oof_df, batch_size=512)\n",
    "dm.setup(stage=\"fit\", fold_n=0)\n",
    "\n",
    "epochs = 5\n",
    "t_max = dm.train_steps * epochs\n",
    "\n",
    "model = StackModel(len(oofs), T_max=t_max)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=epochs)\n",
    "\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f4883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
